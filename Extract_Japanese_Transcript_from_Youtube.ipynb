{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook, based on [this blog post](https://blog.deepgram.com/how-to-use-whisper-openais-speech-recognition-model-in-1-minute/), allows me to extract a text transcript from the audio of a Japanese youtube video using OpenAI's Whisper model. The `small` model offers the best mix of accuracy and speed, but I have decided to use the `medium` model for higher accuracy."
      ],
      "metadata": {
        "id": "dF_E0Q5iy1SM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOvKw2K3kWqK"
      },
      "outputs": [],
      "source": [
        "# Install whisper\n",
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYaGfY1J2VRi"
      },
      "outputs": [],
      "source": [
        "# Pull down some audio to transcribe. The youtube id goes here\n",
        "!pip install yt-dlp\n",
        "!yt-dlp https://www.youtube.com/watch?v=keh4mtwqjCQ --format m4a -o \"youtube_audio.%(ext)s\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vn8SoU9GpV3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uU1Bxv1y6zAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d687a454-2bd0-4f46-d112-664dd3b23d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: whisper: command not found\n"
          ]
        }
      ],
      "source": [
        "# Run whisper\n",
        "!whisper \"/content/youtube_audio.m4a\" --model medium --language Japanese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg2FO0LZgtBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464effe2-fe69-4596-e672-de8e1dd0044a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 3546.963076353073\n"
          ]
        }
      ],
      "source": [
        "end_time = time.time()\n",
        "print(f\"Elapsed time: {end_time - start_time}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}